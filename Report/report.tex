\documentclass[12pt]{article}
\usepackage[nottoc,numbib]{tocbibind}
\usepackage{cite}

\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{enumerate}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}
\usepackage{tikz}
\usepackage{multirow}

% Include Code
\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=R,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

% Include Algorithm
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\floatname{algorithm}{Procedure}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\usepackage[margin=1in]{geometry}
\newenvironment{packed_item}{
\begin{itemize}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{itemize}}

% Typeset Shortcuts
\newcommand{\C}{{\mathbb{C}}}
\newcommand{\F}{{\mathcal{F}}}
\newcommand{\R}{{\mathbb{R}}}
\newcommand{\Z}{{\mathbb{Z}}}
\newcommand{\N}{{\mathbb{N}}}
\newcommand{\Q}{{\mathbb{Q}}}

\DeclareMathOperator{\indep}{\perp\hspace{-.6em}\perp}

  \usepackage{tcolorbox}
  \newcommand{\summary}[1]{
  	\vspace{0.25cm}
  	\begin{tcolorbox}
  		\small{
  			%\textbf{Summary.}
  			#1}
  	\end{tcolorbox}
  }

\newcommand{\norm}[1]{\|{#1}\|}
\newcommand{\Norm}[1]{\left\|{#1}\right\|}
\newcommand{\rank}{{\mathrm{rank}}}
\newcommand{\Var}{\mathrm{Var}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\E}{{\mathbb{E}}}
\newcommand{\I}{{\mathbb{I}}}
\newcommand{\diag}{{\mathrm{diag}}}
\newcommand{\Bias}{\mathrm{Bias}}
\newcommand{\MSE}{\mathrm{MSE}}
\newcommand{\eps}{\varepsilon}
\newcommand{\argmin}{\mathrm{argmin}}
\newcommand{\Conv}{\mathrm{Conv}}
\newcommand{\Int}{\mathrm{int}}
\newcommand{\heart}{\heartsuit}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}

\begin{document}
\begin{titlepage}
	\centering
	
	{\scshape \Large STAT 548 Report 3
\par}
	\vspace{1cm}
	{\huge\bfseries Lifted Parallel Tempering for Training Restricted Boltzmann Machines''
\par}
	\vspace{0.5cm}
	{\Large  Amit Kadan, Saifuddin Syed, Esten Nicolai W{\o}ien
\par}

	\vfill
	Submitted to\par
	{\scshape Dr.~Siamak Ravanbakhsh}\\
		{ \today\par}


% Bottom of the page

\end{titlepage}

\tableofcontents
\newpage

\section{Introduction}
Restricted Boltzmann Machines (RBMs) are Markov random fields with applications including density estimation, 
dimensionality reduction and collaborative filtering.

\section{Restricted Boltzmann Machines}
\input{sec_2_RBM}

\section{Contrastive Divergence}

\section{Tempering Methods}
As we have discussed previously, the problem of learning the model for an RBM can be boiled down to effectively we can approximate $\E_P\left(\frac{\partial E}{\partial \theta}\right)$. In order to do this, we had to resort to Gibbs Sampling. 
Gibbs sampling performs local updates to generate a Markov Chain with stationary distribution $P(\textbf{v},\textbf{h})$ which is complex and multi-modal. Despite the theoretical guaranteed convergence of Gibb's sampling, the local nature of the updates means that chain can have a very difficult time traversing the modes of $P$ and  has a tendency to get trapped exploring the local areas of our sample space of high probability. This means that certain modes are over-represented, while other are under-represented and leading to a poor approximation of our expectation.

Parallel tempering (PT) is a class of Monte Carlo methods first introduced by Geyer in \cite{geyer1991markov} that improve the miximng our our MCMC chain, by simultaneuously running $N$ MCMC chains in parallel but at different temperatures. The higher temperature chains focus on exploration of the state space, while the room temperature chain focus on the accuracy of samples. In order for there to be communication between the hot and room temperature chains, we periodically propose swaps between the chains in such a what that does not propose 


\subsection{Parallel Tempering}
Let $P$ be a Gibbs distribution over some sample space $\Omega$ of the form,
\[P(x)=\frac{1}{Z} \exp(-E(x)).\]
Note that $E$ can be that of an RBM but does not have to be. We define our inverse-temperature space as $\mathcal{B}=[\beta_{\min},1]$, for $0\leq \beta_{\min}<1$. Given $\beta\in\mathcal{B}$, let $P^{(\beta)}$ the probability distribution identified with the un-normalized density $P(x)^\beta$, which we can write
\[P^{(\beta)}(x)= \frac{1}{Z(\beta)} \exp(-\beta E(x)),\]
where $Z(\beta)$ is the partition function. 

Given a sequence of inverse temperatures $0\leq\beta_{\min}= \beta_0<\beta_{1}<\cdots<\beta_N=1$, we define the measure $\tilde{P}$ on $\Omega^{N+1}$ by,
\[\tilde{P}=P^{(\beta_0)}\times\cdots\times P^{(\beta_N)}.\]
In parallel tempering we construct a Markov chain $X_n=(X_n^{0},\cdots, X^{N}_n)$ on $\Omega^N$ with stationary distribution $\tilde{\pi}$. We update $X_n$ by alternate between two different type of dynamics: exploration and communication. 

During the exploration phase, we allow for each $X_n^i$ to independently explore $\Omega$ according to $P^{(\beta_i)}$ via our favourite MCMC algorithm such as Gibb's Sampling. Since MCMC updates of each component $i$ leaves $P^{(\beta_i)}$ invariant, we have the exploration phase leaves $\tilde{P}$ invariant.

During the communication phase, give we propose a swap between the $\beta_i$ and $\beta_j$ components of $X_n$, in other words we swap $ X^i_n$ and $X^j_n$ in $X_n$. To simplify notation, given $x=(x^0,\cdots,x^i,\cdots,x^j,\cdots, x^N)$, we will define $x_{(i,j)}=(x^0,\cdots,x^j,\cdots,x^i,\cdots,x^N)$. So the proposed state during the communication phase is $(X_n)_{(i,j)}$. In order to preserve stationary, we can make this update reversible by accepting this proposed swap according to the Metropolis acceptance,
\begin{align*}
\alpha
&=1\wedge\frac{\tilde{P}((X_n)_{(i,j)})}{\tilde{P}(X_n)}\\
&=1\wedge\frac{P^{(\beta_i)}(X_n^j)P^{(\beta_j)}(X_n^i)}{P^{(\beta_i)}(X_n^i)P^{(\beta_j)}(X_n^j)}\\
&=1\wedge\exp\left[(\beta_j-\beta_i)(E(X_n^j)-E(X_n^i))\right]
\end{align*}

We refer to $(X_n^{i})_{n\geq0}$ as the $i^{th}$ chain, the sequence of states at a particular temperature $\beta_i$. We refer to the sequence $R^i=(X_0^{i},\dots,X_n^i,X_{n+1}^{j},X_{n+2}^{j},\dots)$ as the $i^{th}$ replica. The $i^{th}$ replica follows the trajectory of the $i^{th}$ state as it's temperature changes. In this case, there was a successful swap at time $n$ between temperatures at states $\beta_i$ and $\beta_j$.  

Since the likelihood of acceptance is proportional to the change in temperature, we usually restrict to our swaps to nearest neighbours. 
\subsection{Lifted Parallel Tempering}
In parallel tempering because of detailed balance condition on the temperature the replica must be proposed a swap that can potentially raise or lower the temperature. This  forces the replica to traverse the $\mathcal{B}$ in a random walk fashion and leads to diffusive behaviour. This is not favourable as the goal is to have the information from the high temperature states reach room temperature as quickly as possible, without getting distracted along the way. That is where Lifted Parallel Tempering (LPT) comes to the rescue. LPT is a non-reversible version of PT aims to remedy this diffusive behaviour. Before we introduce it, we will need to introduce the Generalized Metropolis Hastings framework as outlined in \cite{wu_irreversible_2017}.

\subsubsection{Generalized Metropolis-Hastings Framework}
Suppose we probability measure $P$ over measurable space $(\Omega,\mathcal{F})$ and $S:(\Omega,\mathcal{F})to (\Omega,\mathcal{F})$ is a measure preserving involution for $P$. Suppose we have Metropolis-proposal kernel $Q(y|x)$, we will use this to construct a new proposal $\tilde{Q}$ given by $\tilde{Q}(y|x)=Q(S(dy)|x)$. We will then accept this proposal with probability 
\[\alpha(x,y)=\frac{\pi(y)\tilde{Q}(y|x)}{\pi(x)\tilde{Q}(x|y)}.\]
This induces the reversible Metropolis transition kernel, 
\[\tilde{K}(y|x)=\alpha(x,y)\tilde{Q}(y|x)+\left(1-\int\alpha(x,y)\tilde{Q}(y|x)dy\right)\delta_x(y).\]
which has stationary distribution $P$. Since $\tilde{K}$ and $S$ preserve $P$, then so does $K\equiv S\circ \tilde{K}$, which is given by,
\begin{align*}
K(y|x)=\alpha(x,y)Q(y|x)+\left(1-\int\alpha(x,y)Q(y|x)dy\right)\delta_{S(x)}(y).
\end{align*}
Effectively, we make a proposal according to $Q$, which is accepted with probability $\alpha$ and apply $S$ if the proposal is rejected. This in general produces an non-reversible scheme as the composition of two reversible kernels is not necessarily reversible.
\subsubsection{Lifted Parallel Tempering Algorithm}
Suppose we have a partition $P=\{\beta_0,\cdots,\beta_N\}$ for our inverse-temperature space $\mathcal{B}=[\beta_{\min},1]$, where 
\[0\leq \beta_{\min}= \beta_0<\dots\beta_N=1.\]
Similar to PT, we have $N$ additional chains running simultaneously at inverse temperatures according to $P$, with joint distribution $\tilde{\pi}^P=\pi^{(\beta_0)}\times\dots\times\pi^{(\beta_N)}$. We denote the state at time $n$ by $X_n=(X^0_n,\dots, X^N_n)$, where $X^i$ is at temperature $\beta_i$. In addition we introduce the lifted parameters $(\eta_n,\varepsilon_n)\in \{0,1,\dots,N\}\times\{\pm 1\}$. Here $\eta_n$ represents temperature index of the $\eta_0$-th replica and $\varepsilon_n$ represents the direction the replica will attempt to swap, i.e, the next proposed swap will be between $X^{\eta_n}_n$ and $X^{\eta_n+\eps_n}_n$. 

To deal with the boundary cases, note that the replica is at temperature $\beta_0$ or $\beta_N$ then it must be proposed a swap with the state at temperature $\beta_1$ and $\beta_{N-1}$ respectively. So we have
\[(\eta_n,\varepsilon_n)\in \{0,1,\dots,N\}\times\{\pm 1\}\backslash\{(0,-1),(N,1)\}\equiv \mathcal{X}. \]

Let $Z_n=(X_n,\eta_n,\epsilon_n)$ be a Markov chain in enlarged space will be $\Omega^{N+1}\times\mathcal{X}$. Suppose we are working with the deterministic proposal
\[Q(y|z)=\delta_{\phi(z)}(y)\]
given by, 
\begin{align*}
\phi(X,\eta,\eps)=
\begin{cases}
(X_{(\eta,\eta+\eps)},\eta+\eps,\eps) &   0<\eta+\eps<N,\\
(X_{(\eta,\eta+\eps)},\eta+\eps,-\eps) &  \mathrm{Otherwise}.\\
\end{cases}
\end{align*}
We also define the involution $S:\Omega^{N+1}\times\mathcal{X}$ given by,
\begin{align*}
S(X,\eta,\eps)=
\begin{cases}
(X,\eta,-\eps) &   0<\eta+\eps<N,\\
(X,\eta,\eps) &  \mathrm{Otherwise},
\end{cases}
\end{align*}
which preserves the measure $\tilde{\pi}^P\times\mathrm{Unif}(\mathcal{X})$. Together $Q$ and $S$ give us the recipe for the lifted parallel tempering algorithm. Details are outlined in \cite{wu_irreversible_2017}.

\subsection{Deterministic Even/Odd Algorithm}
\subsection{PT for RBM}
\section{Experiments}
\input{sec_5_experiments}
\bibliography{01} 
\bibliographystyle{alpha}
%\section{Code}

\end{document}
